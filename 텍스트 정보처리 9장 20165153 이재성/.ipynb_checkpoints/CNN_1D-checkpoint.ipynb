{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱망 CNN 1D를 이용한 IMDB 감정 분류\n",
    "# 코드 전체가 keras 또는 tensorflow 버전이 달라서 그런것인지 몇몇 결과가 교재와 다르다.\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "25000 train observations\n",
      "25000 test observations\n"
     ]
    }
   ],
   "source": [
    "# 변수 설정\n",
    "max_features = 6000\n",
    "max_length = 400\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), 'train observations')\n",
    "print(len(x_test), 'test observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 단어 대 숫자 매핑 생성\n",
    "wind = imdb.get_word_index()\n",
    "\n",
    "# 실습 화상 강의 때 말씀 하신 부분으로 함수명이 다르다\n",
    "\n",
    "# python3로 dict클래스의 iteritems는 items로 변경되었다.\n",
    "# revind = dict((v,k) for k,v in wind.iteritems()) \n",
    "revind = dict((v,k) for k,v in wind.items()) \n",
    "\n",
    "print (x_train[0])\n",
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역매핑된 딕셔너리를 사용해 디코딩을 하는 함수\n",
    "def decode(sent_list):\n",
    "    new_words = []\n",
    "    \n",
    "    for i in sent_list:\n",
    "        new_words.append(revind[i])\n",
    "        \n",
    "    comb_words = \" \".join(new_words)\n",
    "    \n",
    "    return comb_words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought and but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "print (decode(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "# 293p의 결과는 400L로 나오는데 그 이유는 잘 모르겠다.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 아키텍처 파라미터\n",
    "batch_size = 32\n",
    "embedding_dims = 60\n",
    "num_kernels = 260\n",
    "kernel_size = 3\n",
    "hidden_dims = 300\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,embedding_dims,input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(num_kernels,kernel_size,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 60)           360000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 60)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 260)          47060     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 260)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               78300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 485,661\n",
      "Trainable params: 485,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 81s 130ms/step - loss: 0.4443 - accuracy: 0.7744 - val_loss: 0.2953 - val_accuracy: 0.8806\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.2456 - accuracy: 0.9015 - val_loss: 0.2704 - val_accuracy: 0.8878\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 76s 122ms/step - loss: 0.1590 - accuracy: 0.9391 - val_loss: 0.2724 - val_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205ad2b2310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_split=0.2) # 3개의 에포크지만 역시 많은 시간이 걸린다.\n",
    "# 교재와는 다른 결과를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "y_train_predclass = model.predict_classes(x_train,batch_size=batch_size)\n",
    "y_test_predclass = model.predict_classes(x_test,batch_size=batch_size)\n",
    "\n",
    "y_train_predclass.shape = y_train.shape\n",
    "y_test_predclass.shape = y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CNN 1D  - Train accuracy: 0.965\n",
      "\n",
      "CNN 1D of Training data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     12500\n",
      "           1       0.96      0.97      0.97     12500\n",
      "\n",
      "    accuracy                           0.97     25000\n",
      "   macro avg       0.97      0.97      0.97     25000\n",
      "weighted avg       0.97      0.97      0.97     25000\n",
      "\n",
      "\n",
      "CNN 1D - Train Confusion Matrix\n",
      "\n",
      " Predicted      0      1\n",
      "Actuall                \n",
      "0          12021    479\n",
      "1            390  12110\n",
      "\n",
      "CNN 1D  - Test accuracy: 0.888\n",
      "\n",
      "CNN 1D of Test data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12500\n",
      "           1       0.88      0.89      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n",
      "\n",
      "CNN 1D - Test Confusion Matrix\n",
      "\n",
      " Predicted      0      1\n",
      "Actuall                \n",
      "0          11046   1454\n",
      "1           1345  11155\n"
     ]
    }
   ],
   "source": [
    "# 모델 정확도 및 메트릭 계산\n",
    "# 결과값이 중간중간 값이 다른 것을 확인되고 마지막 결과도 다르다. (297p)\n",
    "\n",
    "print ((\"\\n\\nCNN 1D  - Train accuracy:\"),(round(accuracy_score(y_train,y_train_predclass),3)))\n",
    "print (\"\\nCNN 1D of Training data\\n\",classification_report(y_train, y_train_predclass))\n",
    "print (\"\\nCNN 1D - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, y_train_predclass,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))      \n",
    "\n",
    "print ((\"\\nCNN 1D  - Test accuracy:\"),(round(accuracy_score(y_test,y_test_predclass),3)))\n",
    "print (\"\\nCNN 1D of Test data\\n\",classification_report(y_test, y_test_predclass))\n",
    "print (\"\\nCNN 1D - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, y_test_predclass,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
