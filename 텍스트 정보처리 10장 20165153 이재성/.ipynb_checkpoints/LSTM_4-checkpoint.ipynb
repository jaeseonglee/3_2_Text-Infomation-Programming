{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 파일 읽기\n",
    "with open('bot.txt', 'r') as content_file:\n",
    "    botdata = content_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Questions                                            Answers  \\\n",
      "0               yahoo  a lot of people hear about <bot name=\"name\"/> ...   \n",
      "1        you are lazy                    actually i work 24 hours a day.   \n",
      "2         you are mad                no i am quite logical and rational.   \n",
      "3    you are thinking  i am a thinking machine.<think><set name=\"it\">...   \n",
      "4  you are dividing *            actually i am not too good at division.   \n",
      "\n",
      "                                             QnAcomb  \n",
      "0  yahoo a lot of people hear about <bot name=\"na...  \n",
      "1       you are lazy actually i work 24 hours a day.  \n",
      "2    you are mad no i am quite logical and rational.  \n",
      "3  you are thinking i am a thinking machine.<thin...  \n",
      "4  you are dividing * actually i am not too good ...  \n"
     ]
    }
   ],
   "source": [
    "Questions = []\n",
    "Answers = []\n",
    "\n",
    "for line in botdata.split(\"</pattern>\"):\n",
    "    if \"<pattern>\" in line:\n",
    "        Quesn = line[line.find(\"<pattern>\")+len(\"<pattern>\"):]\n",
    "        Questions.append(Quesn.lower())\n",
    "        \n",
    "for line in botdata.split(\"</template>\"):\n",
    "    if \"<template>\" in line:\n",
    "        Ans = line[line.find(\"<template>\")+len(\"<template>\"):]\n",
    "        Ans = Ans.lower()\n",
    "        Answers.append(Ans.lower())\n",
    "\n",
    "QnAdata = pd.DataFrame(np.column_stack([Questions,Answers]),columns = [\"Questions\",\"Answers\"])\n",
    "QnAdata[\"QnAcomb\"] = QnAdata[\"Questions\"]+\" \"+QnAdata[\"Answers\"]\n",
    "\n",
    "\n",
    "print(QnAdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 3451\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter()\n",
    "\n",
    "for i in range(len(QnAdata)):\n",
    "    for word in nltk.word_tokenize(QnAdata.iloc[i][2]):\n",
    "        counter[word]+=1\n",
    "\n",
    "word2idx = {w:(i+1) for i,(w,_) in enumerate(counter.most_common())}        \n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "vocab_size = len(word2idx)+1\n",
    "\n",
    "print(\"\\n\\nVocabulary size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, maxlen,vocab_size):\n",
    "    indices = np.zeros((maxlen, vocab_size))\n",
    "    for i, w in enumerate(nltk.word_tokenize(sentence)):\n",
    "        if i == maxlen: break\n",
    "        indices[i, word2idx[w]] = 1\n",
    "    return indices\n",
    "\n",
    "\n",
    "def decode(indices, calc_argmax=True):\n",
    "    if calc_argmax:\n",
    "        indices = np.argmax(indices, axis=-1)\n",
    "    return ' '.join(idx2word[x] for x in indices)\n",
    "\n",
    "\n",
    "question_maxlen = 10\n",
    "answer_maxlen = 20\n",
    "\n",
    "def create_questions(question_maxlen,vocab_size):\n",
    "    question_idx = np.zeros(shape=(len(Questions),question_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Questions)):\n",
    "        question = encode(Questions[q],question_maxlen,vocab_size)\n",
    "\n",
    "        question_idx[i] = question \n",
    "    return question_idx\n",
    "\n",
    "quesns_train = create_questions(question_maxlen=question_maxlen,vocab_size=vocab_size)\n",
    "\n",
    "\n",
    "def create_answers(answer_maxlen,vocab_size):\n",
    "    answer_idx = np.zeros(shape=(len(Answers),answer_maxlen,vocab_size))\n",
    "    \n",
    "    for q in range(len(Answers)):\n",
    "        answer = encode(Answers[q],answer_maxlen,vocab_size)\n",
    "\n",
    "        answer_idx[i] = answer \n",
    "    return answer_idx\n",
    "\n",
    "answs_train = create_answers(answer_maxlen=answer_maxlen,vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector,TimeDistributed,ActivityRegularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 3451)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               1832960   \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 3451)          445179    \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 20, 3451)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 3451)          0         \n",
      "=================================================================\n",
      "Total params: 2,278,139\n",
      "Trainable params: 2,278,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "\n",
    "question_layer = Input(shape=(question_maxlen,vocab_size))\n",
    "encoder_rnn = LSTM(n_hidden,dropout=0.2,recurrent_dropout=0.2)(question_layer)\n",
    "repeat_encode = RepeatVector(answer_maxlen)(encoder_rnn)\n",
    "dense_layer = TimeDistributed(Dense(vocab_size))(repeat_encode)\n",
    "regularized_layer = ActivityRegularization(l2=1)(dense_layer)\n",
    "softmax_layer = Activation('softmax')(regularized_layer)\n",
    "\n",
    "model = Model([question_layer],[softmax_layer])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quesns_train_2 = quesns_train.astype('float32')\n",
    "answs_train_2 = answs_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2803 samples, validate on 148 samples\n",
      "Epoch 1/30\n",
      "2803/2803 [==============================] - 35s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 2/30\n",
      "2803/2803 [==============================] - 30s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 3/30\n",
      "2803/2803 [==============================] - 27s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 4/30\n",
      "2803/2803 [==============================] - 27s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 5/30\n",
      "2803/2803 [==============================] - 29s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 6/30\n",
      "2803/2803 [==============================] - 36s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 7/30\n",
      "2803/2803 [==============================] - 36s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 8/30\n",
      "2803/2803 [==============================] - 37s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 9/30\n",
      "2803/2803 [==============================] - 27s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 10/30\n",
      "2803/2803 [==============================] - 27s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 11/30\n",
      "2803/2803 [==============================] - 31s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 12/30\n",
      "2803/2803 [==============================] - 27s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 13/30\n",
      "2803/2803 [==============================] - 29s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 14/30\n",
      "2803/2803 [==============================] - 28s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 15/30\n",
      "2803/2803 [==============================] - 28s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 16/30\n",
      "2803/2803 [==============================] - 28s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 17/30\n",
      "2803/2803 [==============================] - 35s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 18/30\n",
      "2803/2803 [==============================] - 30s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 19/30\n",
      "2803/2803 [==============================] - 30s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 20/30\n",
      "2803/2803 [==============================] - 31s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 21/30\n",
      "2803/2803 [==============================] - 26s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 22/30\n",
      "2803/2803 [==============================] - 23s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 23/30\n",
      "2803/2803 [==============================] - 26s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 24/30\n",
      "2803/2803 [==============================] - 25s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 25/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 26/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 27/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 28/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 29/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n",
      "Epoch 30/30\n",
      "2803/2803 [==============================] - 22s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x155fc485b80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(quesns_train_2, answs_train_2,batch_size=32,epochs=30,validation_split=0.05) # 오래 걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "ans_pred = model.predict(quesns_train_2[0:3])\n",
    "\n",
    "print (decode(ans_pred[0]))\n",
    "print (decode(ans_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
